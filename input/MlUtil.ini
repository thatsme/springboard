## Random Forest Classifier base configuration parameters
[RandomForestClassifier]
bootstrap = True
ccp_alpha = 0.0
class_weight = balanced
criterion = gini
max_depth = 4
max_features = auto
max_leaf_nodes = None
max_samples = None
min_impurity_decrease = 0.0
min_impurity_split = 2
min_samples_leaf = 1
min_samples_split = 2
min_weight_fraction_leaf = 0.0
n_estimators = 100
n_jobs = -1
oob_score = False
random_state = 42
verbose = 0
warm_start = False

## GS --> Grid Test
[RandomForestClassifierGS_1]
n_estimators = [5,10,50,100,250]
max_depth = [2,4,8,16,32,None]

## GS --> Grid Test
[RandomForestClassifierGS_2]
n_estimators = [10,50,100,250,500]
max_depth = [4,8,16,32,48,None]

## GS --> Grid Test
[RandomForestClassifierGS_3]
n_estimators = [50,100,250,500, 1000]
max_depth = [8,16,32,48, 96,None]

## GS --> Grid Test
[RandomForestClassifierGS_4]
n_estimators = [100, 300, 500, 800, 1200]
min_samples_split = [2, 5, 10, 15, 100]
min_samples_leaf = [1, 2, 5, 10] 

## GS --> Grid Test
[RandomForestClassifierGS_5]
criterion = [gini,entropy]
max_features = [sqrt, log2]

## RS --> Random Test on Random Forest Classifier
[RandomForestClassifierRS_1]
n_estimators = [200,400,600,800,1000,1200,1400,1600,1800,2000]
max_features = [auto,sqrt]
max_depth = [10,20,30,40,50,60,70,80,90,100,110,None]
min_samples_split = [2,5,10,15]
min_samples_leaf = [1,2,4,6]
max_leaf_nodes = [50,100,200]
bootstrap = [True,False]

## Extra Trees Regressor  base configuration parameters
[ExtraTreesRegressor]
n_estimators = 10
criterion = mse
max_depth = None
min_samples_splitint = 2
min_samples_leaf = 1
min_weight_fraction_leaf = 0
max_features = auto
max_leaf_nodes = None
min_impurity_decrease = 0
min_impurity_split = 0.00000001
bootstrap = False
oob_score = False
n_jobs = None
random_state = 42
verbose = 0
warm_start = False
ccp_alpha = 0.0
max_samples = None

## RS --> Random Test on Extra Trees Regressor
[ExtraTreesRegressorRS_1]
n_estimators = [10, 50, 100, 200, 500, 1000]
criterion = [mse,mae]
max_depth =  [10,20,30,40,50,60,70,80,90,100,110,None]

## Extra Trees Classifier  base configuration parameters
[ExtraTreesClassifier]
n_estimators = 10
criterion = gini
max_depth = None
min_samples_splitint = 2
min_samples_leaf = 1
min_weight_fraction_leaf = 0
max_features = auto
max_leaf_nodes = None
min_impurity_decrease = 0
min_impurity_split = 0.00000001
bootstrap = False
oob_score = False
n_jobs = None
random_state = 42
verbose = 0
warm_start = False
class_weight = None
ccp_alpha = 0.0
max_samples = None

## RS --> Random Test on Extra Trees Classifier
[ExtraTreesClassifierRS_1]


## Ada Boost Classifier  base configuration parameters
[AdaBoostClassifier]
base_estimator = None
n_estimators = 50
learning_rate = 1.0
algorithm = SAMMER.R
random_state = 42

## RS --> Random Test on Ada Boost Classifier
[AdaBoostClassifierRS_1]

## Gradient Boosting Classifier  base configuration parameters
[GradientBoostingClassifier]
loss = deviance
learning_rate = 0.1
n_estimators = 100
subsample = 1.0
criterion = friedman_mse
min_samples_splitint = 2
min_samples_leaf = 1
min_weight_fraction_leaf = 0.0
max_depth = 3
min_impurity_decrease = 0.0
min_impurity_split = 0.00000001
init = None
random_state = 42
max_features = None
verbose = 0
max_leaf_nodes = None
warm_start = None
validation_fraction = 0.1
n_iter_no_change = None
tol = 0.0001
ccp_alpha = 0.0

## RS --> Random Test on Gradient Boosting Classifier
[GradientBoostingClassifierRS_1]



